<!DOCTYPE html><html lang="zh-Hans"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="âœ¨Deep-High-Resolution Representation Learning for Cross-Resolution Person Re-identification"><meta name="keywords" content="è¡Œäººé‡è¯†åˆ«,è®ºæ–‡"><meta name="author" content="GeYu"><meta name="copyright" content="GeYu"><title>âœ¨Deep-High-Resolution Representation Learning for Cross-Resolution Person Re-identification | Yu's Blog</title><link rel="shortcut icon" href="/favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'å¤åˆ¶æˆåŠŸ',
    error: 'å¤åˆ¶é”™è¯¯',
    noSupport: 'æµè§ˆå™¨ä¸æ”¯æŒ'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="åˆ‡æ¢æ–‡ç« è¯¦æƒ…">åˆ‡æ¢ç«™ç‚¹æ¦‚è§ˆ</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">ç›®å½•</div><div class="sidebar-toc__progress"><span class="progress-notice">ä½ å·²ç»è¯»äº†</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Contents-ğŸ—’"><span class="toc-number">1.</span> <span class="toc-text">Contents ğŸ—’</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction-ğŸ—’"><span class="toc-number">2.</span> <span class="toc-text">Introduction ğŸ—’</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Usage-ğŸ”§"><span class="toc-number">3.</span> <span class="toc-text">Usage ğŸ”§</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Results-ğŸ†"><span class="toc-number">4.</span> <span class="toc-text">Results ğŸ†</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Acknowledgements-ğŸ‘"><span class="toc-number">5.</span> <span class="toc-text">Acknowledgements ğŸ‘</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://images5.alphacoders.com/423/423529.jpg"></div><div class="author-info__name text-center">GeYu</div><div class="author-info__description text-center">Do what you want to do !</div><div class="follow-button"><a href="https://github.com/NUISTGY">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">æ–‡ç« </span><span class="pull-right">225</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">æ ‡ç­¾</span><span class="pull-right">82</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">åˆ†ç±»</span><span class="pull-right">45</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://i.328888.xyz/2022/12/21/ARudF.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Yu's Blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a></span></div><div id="post-info"><div id="post-title">âœ¨Deep-High-Resolution Representation Learning for Cross-Resolution Person Re-identification</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-10-07</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/è¡Œäººé‡è¯†åˆ«/">è¡Œäººé‡è¯†åˆ«</a><div class="post-meta-wordcount"><span>å­—æ•°æ€»è®¡: </span><span class="word-count">390</span><span class="post-meta__separator">|</span><span>é˜…è¯»æ—¶é•¿: 2 åˆ†é’Ÿ</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><script src="/assets/js/APlayer.min.js"> </script><div align="center">

<p><a href="https://ieeexplore.ieee.org/document/9591273/authors#citations" target="_blank" rel="noopener"><strong><front size="5">Journal of IEEE TIP (SCI-Q1 Top)</front></strong></a></p>
<center>
G. Zhang, ğŸ‘‰Y. GeğŸ‘ˆ, Z. Dong, H. Wang, Y. Zheng and S. Chen
</center>

<p><img src="https://img.gejiba.com/images/de85252fec31e625fecf220fa7b686b8.png" alt></p>
</div>

<h2 id="Contents-ğŸ—’"><a href="#Contents-ğŸ—’" class="headerlink" title="Contents ğŸ—’"></a><a id="contents-">Contents ğŸ—’</a></h2><ul>
<li><a href="#contents-"><a id="contents-">Contents ğŸ—’</a></a></li>
<li><a href="#introduction-"><a id="introduction-">Introduction ğŸ—’</a></a></li>
<li><a href="#usage-"><a id="usage-">Usage ğŸ”§</a></a></li>
<li><a href="#results-"><a id="result-">Results ğŸ†</a></a></li>
<li><a href="#acknowledgements-"><a id="acknowledgements-">Acknowledgements ğŸ‘</a></a></li>
</ul>
<h2 id="Introduction-ğŸ—’"><a href="#Introduction-ğŸ—’" class="headerlink" title="Introduction ğŸ—’"></a><a id="introduction-">Introduction ğŸ—’</a></h2><p>We propose a Deep High-Resolution Pseudo-Siamese Framework (PS-HRNet) to solve the cross-resolution person re-ID problem. Specifically, in order to restore the resolution of low-resolution images and make reasonable use of different channel information of feature maps, we introduce and innovate VDSR module with channel attention (CA) mechanism, named as VDSR-CA. Then we reform the HRNet by designing a novel representation head to extract discriminating features, named as HRNet-ReID. In addition, a pseudo-siamese framework is constructed to reduce the difference of feature distributions between low-resolution images and high-resolution images. The experimental results on five cross-resolution person datasets verify the effectiveness of our proposed approach. Compared with the state-of-the-art methods, our proposed PS-HRNet improves 3.4%, 6.2%, 2.5%,1.1% and 4.2% at Rank-1 on MLR-Market-1501, MLR-CUHK03, MLR-VIPeR, MLR-DukeMTMC-reID, and CAVIAR datasets, respectively.</p>
<h2 id="Usage-ğŸ”§"><a href="#Usage-ğŸ”§" class="headerlink" title="Usage ğŸ”§"></a><a id="usage-">Usage ğŸ”§</a></h2><p>We use apex (A PyTorch Extension) a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training. Some of the code here will be included in upstream Pytorch eventually. The intention of Apex is to make up-to-date utilities available to users as quickly as possible.Installation instructions can be found here: <a href="https://github.com/NVIDIA/apex#quick-start" target="_blank" rel="noopener">https://github.com/NVIDIA/apex#quick-start</a>.</p>
<p>We display the process of the algorithm as an ipynb file, you can use jupyter notebook to view and run it.</p>
<p>You may need HRNet-W32-C ImageNet pretrained models or learn more about HRNet: <a href="https://github.com/HRNet/HRNet-Image-Classification.git" target="_blank" rel="noopener">https://github.com/HRNet/HRNet-Image-Classification.git</a>.</p>
<p>Wanna know more detail of the first phaseï¼Ÿ Check thisï¼š<a href="https://github.com/NUISTGY/Person-re-identification-based-on-HRNet" target="_blank" rel="noopener">https://github.com/NUISTGY/Person-re-identification-based-on-HRNet</a></p>
<h2 id="Results-ğŸ†"><a href="#Results-ğŸ†" class="headerlink" title="Results ğŸ†"></a><a id="result-">Results ğŸ†</a></h2><div align="center">

<p><img src="https://img.gejiba.com/images/6670ce1bd1696c28e0fedd4fbefd676f.png" alt></p>
</div>

<h2 id="Acknowledgements-ğŸ‘"><a href="#Acknowledgements-ğŸ‘" class="headerlink" title="Acknowledgements ğŸ‘"></a><a id="acknowledgements-">Acknowledgements ğŸ‘</a></h2><ul>
<li>This code is built on <a href="https://github.com/HRNet/HRNet-Image-Classification" target="_blank" rel="noopener">HRNet-Image-Classification</a> and <a href="https://github.com/layumi/Person_reID_baseline_pytorch" target="_blank" rel="noopener">Person_reID_baseline_pytorch</a>. We thank the authors for sharing their codes. To the great spirit of open source!</li>
<li>Thank <a href="https://github.com/dzc2000" target="_blank" rel="noopener">Z.Dong</a> and <a href="https://github.com/Rockdow" target="_blank" rel="noopener">H.Wang</a>, they are the most important contributors to the related work of the experiment. If you have any questions in the process of testing, you can send them by email or pose issues.</li>
<li>Thanks for the right to use the GPU workstation provided by Nanyang Technological University.</li>
</ul>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">æ–‡ç« ä½œè€…: </span><span class="post-copyright-info"><a href="mailto:undefined">GeYu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">æ–‡ç« é“¾æ¥: </span><span class="post-copyright-info"><a href="https://nuistgy.github.io/2021/10/07/PSHRNet/">https://nuistgy.github.io/2021/10/07/PSHRNet/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">ç‰ˆæƒå£°æ˜: </span><span class="post-copyright-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥è‡ª <a href="https://nuistgy.github.io">Yu's Blog</a>ï¼</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/è¡Œäººé‡è¯†åˆ«/">è¡Œäººé‡è¯†åˆ«</a><a class="post-meta__tags" href="/tags/è®ºæ–‡/">è®ºæ–‡</a></div><div class="addthis_inline_share_toolbox pull-right"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5befa2f76de7c6b5" async></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2022/09/06/mybatisâ€”â€”è§£å†³å±æ€§åå’Œæ•°æ®åº“å­—æ®µåä¸ä¸€è‡´é—®é¢˜ï¼ˆæ³¨è§£æ–¹å¼)/"><i class="fa fa-chevron-left">  </i><span>MyBatisâ€”â€”è§£å†³å±æ€§åå’Œæ•°æ®åº“å­—æ®µåä¸ä¸€è‡´</span></a></div><div class="next-post pull-right"><a href="/2020/07/15/è®ºæ–‡ç¬”è®°(ä¸€)/"><span>Deep Low-Resolution Person Re-Identificationé˜…è¯»ç¬”è®°</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://i.328888.xyz/2022/12/21/ARudF.png)"><div class="layout" id="footer"><div class="copyright">&copy;2015 - 2023 By GeYu</div><div class="framework-info"><span>é©±åŠ¨ - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>ä¸»é¢˜ - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">Enjoy the cyber world!</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>